{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUtlXvyxcF3xP3UAuFeiLQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatima-asad/deep/blob/main/untitled83.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ijGKTlAlRwbc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,Embedding,SimpleRNN,Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"machine learning is changing the world\",\n",
        "    \"deep learning uses neural networks\",\n",
        "    \"recurrent neural networks process sequences\",\n",
        "    \"lstm handles long term dependencies\",\n",
        "    \"gru is a simpler recurrent unit\",\n",
        "    \"natural language processing uses text data\",\n",
        "    \"python is popular for data science\",\n",
        "    \"pandas and numpy help data analysis\",\n",
        "    \"tensorflow and keras build neural models\",\n",
        "    \"rnn works well with time series\",\n",
        "    \"neural networks learn from data\",\n",
        "    \"ai improves healthcare systems\",\n",
        "    \"data science solves real problems\",\n",
        "    \"models improve with more data\",\n",
        "    \"training neural networks takes time\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "t4iybV8MR4G3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(sentences,columns=['poem'])"
      ],
      "metadata": {
        "id": "HdYKxvLiR9aH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ijBv6WknSFyW",
        "outputId": "afc47aff-0392-4b77-965a-a43aa2c9cc8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          poem\n",
              "0       machine learning is changing the world\n",
              "1           deep learning uses neural networks\n",
              "2  recurrent neural networks process sequences\n",
              "3          lstm handles long term dependencies\n",
              "4              gru is a simpler recurrent unit"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1e87342-bd57-4f55-8c58-c36a5469147f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>poem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>machine learning is changing the world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>deep learning uses neural networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>recurrent neural networks process sequences</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lstm handles long term dependencies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gru is a simpler recurrent unit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1e87342-bd57-4f55-8c58-c36a5469147f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1e87342-bd57-4f55-8c58-c36a5469147f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1e87342-bd57-4f55-8c58-c36a5469147f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-259acf38-2500-49c7-8927-6c1312532be9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-259acf38-2500-49c7-8927-6c1312532be9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-259acf38-2500-49c7-8927-6c1312532be9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"poem\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"rnn works well with time series\",\n          \"ai improves healthcare systems\",\n          \"machine learning is changing the world\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poem=df['poem']"
      ],
      "metadata": {
        "id": "xO-VyqqDSkvv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "translator=str.maketrans(string.punctuation,' '*len(string.punctuation))\n",
        "poem=poem.apply(lambda x:x.translate(translator))"
      ],
      "metadata": {
        "id": "8oTwHF9pSKXQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vocab_size=100\n",
        "tokenize=Tokenizer(num_words=vocab_size)\n",
        "tokenize.fit_on_texts(poem)"
      ],
      "metadata": {
        "id": "ipgM2OC0ShnF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index=tokenize.word_index\n",
        "print(len(word_index))\n",
        "list(word_index.items())[:10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRl6Ec4lTuVM",
        "outputId": "070f64f7-bc05-42f3-a9fe-9c39dee6cb8b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('data', 1),\n",
              " ('neural', 2),\n",
              " ('networks', 3),\n",
              " ('is', 4),\n",
              " ('learning', 5),\n",
              " ('uses', 6),\n",
              " ('recurrent', 7),\n",
              " ('science', 8),\n",
              " ('and', 9),\n",
              " ('models', 10)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence=tokenize.texts_to_sequences(poem)"
      ],
      "metadata": {
        "id": "n3HaOSxqUKwS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(poem[i])\n",
        "    print(sequence[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYVcQh11Xh4i",
        "outputId": "b3815163-2905-4db3-ee47-50c35cd1b315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "machine learning is changing the world\n",
            "[13, 5, 4, 14, 15, 16]\n",
            "deep learning uses neural networks\n",
            "[17, 5, 6, 2, 3]\n",
            "recurrent neural networks process sequences\n",
            "[7, 2, 3, 18, 19]\n",
            "lstm handles long term dependencies\n",
            "[20, 21, 22, 23, 24]\n",
            "gru is a simpler recurrent unit\n",
            "[25, 4, 26, 27, 7, 28]\n",
            "natural language processing uses text data\n",
            "[29, 30, 31, 6, 32, 1]\n",
            "python is popular for data science\n",
            "[33, 4, 34, 35, 1, 8]\n",
            "pandas and numpy help data analysis\n",
            "[36, 9, 37, 38, 1, 39]\n",
            "tensorflow and keras build neural models\n",
            "[40, 9, 41, 42, 2, 10]\n",
            "rnn works well with time series\n",
            "[43, 44, 45, 11, 12, 46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "for sequence in sequence:\n",
        "    for i in range(1,len(sequence)):\n",
        "        input_seq=sequence[:i]\n",
        "        output_seq=sequence[i]\n",
        "        X.append(sequence[:i])\n",
        "        Y.append(sequence[i])"
      ],
      "metadata": {
        "id": "NDCm03I8Xt3m"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=max(len(x) for x in X)\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFzv5h0tYFlj",
        "outputId": "ab12b26d-aa15-451e-993c-10ddb16b84b6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "X_padded=tf.keras.preprocessing.sequence.pad_sequences(X,maxlen=max_len,padding='pre')"
      ],
      "metadata": {
        "id": "23tXMJ9aYPnM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=np.array(Y)"
      ],
      "metadata": {
        "id": "TJ8E8AzIYS4P"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_hot=to_categorical(y,num_classes=vocab_size+1)"
      ],
      "metadata": {
        "id": "40lmA1z2Yboo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, LSTM,GRU\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "YqimVCUkYjr2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emdedding_dim=50\n",
        "rnn_unit=128"
      ],
      "metadata": {
        "id": "gBwY0vMcY9od"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model=Sequential()\n",
        "lstm_model.add(Embedding(input_dim=vocab_size,output_dim=emdedding_dim))\n",
        "lstm_model.add(LSTM(rnn_unit))\n",
        "lstm_model.add(Dense(vocab_size + 1,activation='softmax'))"
      ],
      "metadata": {
        "id": "k5o9ekLCYq2w"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "w6sqVX6zZM8t"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_lstm=lstm_model.fit(\n",
        "    X_padded,y_hot,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WxkHuA5Y5fH",
        "outputId": "e31fddb4-9e89-4e39-d12d-9786222ee602"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 460ms/step - accuracy: 0.0232 - loss: 4.6159 - val_accuracy: 0.0000e+00 - val_loss: 4.6141\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0593 - loss: 4.6067 - val_accuracy: 0.0714 - val_loss: 4.6119\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.0954 - loss: 4.5972 - val_accuracy: 0.0714 - val_loss: 4.6095\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1082 - loss: 4.5860 - val_accuracy: 0.0714 - val_loss: 4.6066\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1418 - loss: 4.5735 - val_accuracy: 0.0714 - val_loss: 4.6029\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1418 - loss: 4.5574 - val_accuracy: 0.0714 - val_loss: 4.5982\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1210 - loss: 4.5381 - val_accuracy: 0.0714 - val_loss: 4.5918\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.1082 - loss: 4.5058 - val_accuracy: 0.0714 - val_loss: 4.5833\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0978 - loss: 4.4578 - val_accuracy: 0.0714 - val_loss: 4.5735\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.1651 - loss: 4.3906 - val_accuracy: 0.0714 - val_loss: 4.5648\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.1442 - loss: 4.2926 - val_accuracy: 0.0714 - val_loss: 4.5684\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.1675 - loss: 4.1481 - val_accuracy: 0.0714 - val_loss: 4.6219\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.1546 - loss: 3.9993 - val_accuracy: 0.0714 - val_loss: 4.8034\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1314 - loss: 3.7937 - val_accuracy: 0.0000e+00 - val_loss: 5.1787\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1522 - loss: 3.6872 - val_accuracy: 0.0000e+00 - val_loss: 5.6027\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0721 - loss: 3.7673 - val_accuracy: 0.0000e+00 - val_loss: 5.8869\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0825 - loss: 3.6731 - val_accuracy: 0.0000e+00 - val_loss: 6.0495\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.0721 - loss: 3.5961 - val_accuracy: 0.0000e+00 - val_loss: 6.1265\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.1571 - loss: 3.5952 - val_accuracy: 0.1429 - val_loss: 6.1395\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.1418 - loss: 3.5690 - val_accuracy: 0.1429 - val_loss: 6.1254\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1106 - loss: 3.5146 - val_accuracy: 0.1429 - val_loss: 6.1130\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.1186 - loss: 3.4926 - val_accuracy: 0.1429 - val_loss: 6.1125\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.1338 - loss: 3.4669 - val_accuracy: 0.1429 - val_loss: 6.1292\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1803 - loss: 3.5119 - val_accuracy: 0.0714 - val_loss: 6.1597\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.1755 - loss: 3.4141 - val_accuracy: 0.0714 - val_loss: 6.2199\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.1338 - loss: 3.4482 - val_accuracy: 0.0714 - val_loss: 6.2967\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1755 - loss: 3.3774 - val_accuracy: 0.0714 - val_loss: 6.4031\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.1442 - loss: 3.3709 - val_accuracy: 0.0714 - val_loss: 6.5191\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.1779 - loss: 3.3226 - val_accuracy: 0.0714 - val_loss: 6.6382\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.1987 - loss: 3.2941 - val_accuracy: 0.0714 - val_loss: 6.7220\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1755 - loss: 3.2552 - val_accuracy: 0.0714 - val_loss: 6.7833\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.1779 - loss: 3.1898 - val_accuracy: 0.1429 - val_loss: 6.8198\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.1931 - loss: 3.2280 - val_accuracy: 0.1429 - val_loss: 6.8705\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.1803 - loss: 3.1901 - val_accuracy: 0.1429 - val_loss: 6.9422\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.2292 - loss: 3.1260 - val_accuracy: 0.1429 - val_loss: 7.0334\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1571 - loss: 3.1361 - val_accuracy: 0.1429 - val_loss: 7.1164\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1779 - loss: 3.0403 - val_accuracy: 0.1429 - val_loss: 7.1667\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.1675 - loss: 3.0485 - val_accuracy: 0.1429 - val_loss: 7.1882\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.1779 - loss: 2.9429 - val_accuracy: 0.1429 - val_loss: 7.1806\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.2268 - loss: 2.8889 - val_accuracy: 0.1429 - val_loss: 7.1840\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.1851 - loss: 2.9314 - val_accuracy: 0.0714 - val_loss: 7.2131\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.2372 - loss: 2.7967 - val_accuracy: 0.1429 - val_loss: 7.2448\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2420 - loss: 2.8541 - val_accuracy: 0.1429 - val_loss: 7.2585\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.2372 - loss: 2.6885 - val_accuracy: 0.1429 - val_loss: 7.2620\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.2476 - loss: 2.6454 - val_accuracy: 0.1429 - val_loss: 7.2731\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.3117 - loss: 2.6586 - val_accuracy: 0.1429 - val_loss: 7.2937\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3325 - loss: 2.5591 - val_accuracy: 0.1429 - val_loss: 7.3178\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3221 - loss: 2.5582 - val_accuracy: 0.1429 - val_loss: 7.3506\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3325 - loss: 2.5142 - val_accuracy: 0.1429 - val_loss: 7.3757\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3558 - loss: 2.4714 - val_accuracy: 0.1429 - val_loss: 7.3957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word={}\n",
        "for word,index in word_index.items():\n",
        "    index_to_word[index]=word"
      ],
      "metadata": {
        "id": "QHpGKAORaHMR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6ViTcBEaVNe",
        "outputId": "d1213048-b824-46fe-b4ee-a89e97de7331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'data',\n",
              " 2: 'neural',\n",
              " 3: 'networks',\n",
              " 4: 'is',\n",
              " 5: 'learning',\n",
              " 6: 'uses',\n",
              " 7: 'recurrent',\n",
              " 8: 'science',\n",
              " 9: 'and',\n",
              " 10: 'models',\n",
              " 11: 'with',\n",
              " 12: 'time',\n",
              " 13: 'machine',\n",
              " 14: 'changing',\n",
              " 15: 'the',\n",
              " 16: 'world',\n",
              " 17: 'deep',\n",
              " 18: 'process',\n",
              " 19: 'sequences',\n",
              " 20: 'lstm',\n",
              " 21: 'handles',\n",
              " 22: 'long',\n",
              " 23: 'term',\n",
              " 24: 'dependencies',\n",
              " 25: 'gru',\n",
              " 26: 'a',\n",
              " 27: 'simpler',\n",
              " 28: 'unit',\n",
              " 29: 'natural',\n",
              " 30: 'language',\n",
              " 31: 'processing',\n",
              " 32: 'text',\n",
              " 33: 'python',\n",
              " 34: 'popular',\n",
              " 35: 'for',\n",
              " 36: 'pandas',\n",
              " 37: 'numpy',\n",
              " 38: 'help',\n",
              " 39: 'analysis',\n",
              " 40: 'tensorflow',\n",
              " 41: 'keras',\n",
              " 42: 'build',\n",
              " 43: 'rnn',\n",
              " 44: 'works',\n",
              " 45: 'well',\n",
              " 46: 'series',\n",
              " 47: 'learn',\n",
              " 48: 'from',\n",
              " 49: 'ai',\n",
              " 50: 'improves',\n",
              " 51: 'healthcare',\n",
              " 52: 'systems',\n",
              " 53: 'solves',\n",
              " 54: 'real',\n",
              " 55: 'problems',\n",
              " 56: 'improve',\n",
              " 57: 'more',\n",
              " 58: 'training',\n",
              " 59: 'takes'}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predictor(model, tokenizer, text, max_len):\n",
        "    text = text.lower()\n",
        "    seq = tokenizer.texts_to_sequences([text])[0]\n",
        "    seq = pad_sequences([seq], maxlen=max_len, padding='pre')\n",
        "    pred = model.predict(seq, verbose=0)\n",
        "    index = np.argmax(pred, axis=-1)[0]\n",
        "    return index_to_word.get(index, \"\")\n"
      ],
      "metadata": {
        "id": "SeY2WmuNmI5y"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, tokenizer, max_len, seed_text, n_words):\n",
        "    for i in range(n_words):\n",
        "        next_word = predictor(model, tokenizer, seed_text, max_len)\n",
        "        if next_word == \"\":\n",
        "            break\n",
        "        seed_text += \" \" + next_word\n",
        "    return seed_text\n"
      ],
      "metadata": {
        "id": "1nIZTxFylym2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed=\"deep learning\"\n",
        "generate=generate(lstm_model,tokenize,max_len,seed,5)\n",
        "print(generate)"
      ],
      "metadata": {
        "id": "88jmd1Rql3gC",
        "outputId": "1466ee33-a0b5-46d6-fc15-3b231730b2e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deep learning is networks networks data data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "id": "QLVM8KjCaX8D"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictor(model,Tokenizer,text,max_len):\n",
        "  text=text.lower()\n",
        "  seq=tokenize.texts_to_sequences([text])[0]\n",
        "  seq=pad_sequences([seq],maxlen=max_len,padding='pre')\n",
        "  pred=model.predict(seq)\n",
        "  index=np.argmax(pred)\n",
        "  return index_to_word[index]"
      ],
      "metadata": {
        "id": "Jj8mR1Wwag3a"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictori(model,Tokenizer,text,max_len):\n",
        "  text=text.lower()\n",
        "  text=text.translate(translator)\n",
        "  seq=Tokenizer.texts_to_sequences([text])\n",
        "  # Corrected line: removed the extra list wrapping around 'seq'\n",
        "  seq=pad_sequences(seq,maxlen=max_len,padding='pre')\n",
        "  pred=model.predict(seq,verbose=0)\n",
        "  index=np.argmax(pred)\n",
        "  return index_to_word[index]\n",
        "\n"
      ],
      "metadata": {
        "id": "hApYOp1udyKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def predictorer(model, tokenizer, text, max_len):\n",
        "    text = text.lower()\n",
        "\n",
        "    seq = tokenizer.texts_to_sequences([text])[0]\n",
        "    seq = pad_sequences([seq], maxlen=max_len, padding='pre')\n",
        "\n",
        "    pred = model.predict(seq, verbose=0)\n",
        "    index = np.argmax(pred, axis=-1)[0]\n",
        "\n",
        "    return index_to_word.get(index, \"\")\n"
      ],
      "metadata": {
        "id": "FWu3Z9vueYaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"machine learning is \"\n",
        "next_word = predictorer(lstm_model, tokenize, seed_text, max_len)\n",
        "\n",
        "print(seed_text, next_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNrw-g3DelSg",
        "outputId": "755c0143-2c1c-428f-f3b9-7c6eabaaabb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "machine learning is  uses\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sed_text=\"machine learning is\"\n",
        "next_word=predictorer(lstm_model,tokenize,sed_text,max_len)\n",
        "print(sed_text,next_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYfxwS8MdbDW",
        "outputId": "8c8abfd5-7aaa-4230-857d-e4a775e7be2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "machine learning is is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model,tokenizer,max_len,seed_text,n_words):\n",
        "  for i in range(n_words):\n",
        "    next_word=predictorer(model,tokenizer,seed_text,max_len)\n",
        "    if next_word ==\"\":\n",
        "       break\n",
        "    seed_text +=\" \" + next_word\n",
        "    return seed_text"
      ],
      "metadata": {
        "id": "3GRqyX7YiKZD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed=\"deep learning\"\n",
        "generate=generate(lstm_model,tokenize,max_len,seed,5)\n",
        "print(generate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "1tJy8pUPirAX",
        "outputId": "cbb0bd44-865f-41bf-9564-e8228e7c6e52"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'predictorer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2765149582.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"deep learning\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-176085609.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(model, tokenizer, max_len, seed_text, n_words)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnext_word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnext_word\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predictorer' is not defined"
          ]
        }
      ]
    }
  ]
}